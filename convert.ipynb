{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mstart load model\u001b[0m\n",
      "INFO:tensorflow:Linked TensorRT version: (8, 5, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 5, 2)\n",
      "\u001b[92mload model successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 21:20:40.292031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:40.368412: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:40.368782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:40.373915: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:40.374307: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:40.374569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:41.678951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:41.679383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:41.679517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-05 21:20:41.679727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:41.679988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7157 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 21:20:46.730202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.730456: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-08-05 21:20:46.731005: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-08-05 21:20:46.732433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.732784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.733039: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.733365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.733479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-05 21:20:46.733665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:46.733837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7157 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing prior device assignments in loaded saved model\n",
      "INFO:tensorflow:Automatic mixed precision has been deactivated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 21:20:51.975695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.976008: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-08-05 21:20:51.976298: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-08-05 21:20:51.977399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.977780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.978080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.978426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.978534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-05 21:20:51.978769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 21:20:51.978905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7157 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n",
      "2023-08-05 21:20:52.755388: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:210] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2023-08-05 21:20:53.072652: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:952] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- Mul -> 2x\n",
      "\t- NoOp -> 2x\n",
      "\t- Placeholder -> 2x\n",
      "\t- Reshape -> 2x\n",
      "\t- ExpandDims -> 1x\n",
      "\t- Split -> 1x\n",
      "\t- Squeeze -> 1x\n",
      "\t- StridedSlice -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 12\n",
      "\t- Total nonconverted OP Types: 8\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2023-08-05 21:20:53.191588: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1280] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 2 TRT Engines with  at least minimum_segment_size=3 nodes.\n",
      "2023-08-05 21:20:53.195190: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:802] Number of TensorRT candidate segments: 2\n",
      "2023-08-05 21:20:53.539141: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 0 consisting of 404 nodes by TRTEngineOp_000_000.\n",
      "2023-08-05 21:20:53.541475: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 1 consisting of 40 nodes by TRTEngineOp_000_001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find TRTEngineOp_000_000 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_001 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: ./model/saved_model_trt/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "print(\"\\033[92mstart load model\\033[0m\")\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=\"./model/saved_model\")\n",
    "print(\"\\033[92mload model successfully\\033[0m\")\n",
    "converter.convert()\n",
    "converter.save(\"./model/saved_model_trt\")\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 定义一个函数来读取图像，这个函数需要根据你的实际情况来实现\n",
    "def load_images(file_name):\n",
    "    # 这里需要你自己实现如何从file_name读取图像并返回numpy数组\n",
    "    pass\n",
    "\n",
    "# 1. 加载已经训练好的TensorFlow模型\n",
    "saved_model_dir = './model/saved_model' # 请替换为你的模型路径\n",
    "model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "# 2. 使用TensorRT进行模型优化\n",
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "params = params._replace(max_workspace_size_bytes=(1<<32)) # 修改workspace大小\n",
    "params = params._replace(precision_mode=\"FP16\") # 设置推理精度\n",
    "params = params._replace(maximum_cached_engines=100) # 设置最大缓存引擎数量\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=params\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# 3. 对模型进行序列化并保存\n",
    "saved_model_dir_trt = 'path_to_save_trt_model' # 请替换为你想要保存TRT模型的路径\n",
    "converter.save(saved_model_dir_trt)\n",
    "\n",
    "# 4. 加载优化后的模型进行推理\n",
    "root = tf.saved_model.load(saved_model_dir_trt)\n",
    "concrete_func = root.signatures['serving_default']\n",
    "\n",
    "# 读取输入数据\n",
    "test_dir = '/path_to_your_test_data' # 请替换为你的测试数据目录\n",
    "test_data_files = glob(os.path.join(test_dir, '*.png')) # 假设你的测试数据是PNG图像\n",
    "test_data = [load_images(file) for file in test_data_files]\n",
    "\n",
    "# 对每一个输入数据进行推理，并保存结果\n",
    "results = []\n",
    "for x in test_data:\n",
    "    # 增加一个维度以匹配模型的输入要求\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = concrete_func(x)\n",
    "    results.append(y)\n",
    "\n",
    "# 在这里，results列表中包含了所有输入数据的推理结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from model import *\n",
    "\n",
    "saved_model_dir = \"./model/saved_model\"\n",
    "test_dir = '/simple/low' # 请替换为你的测试数据目录\n",
    "saved_model_dir_trt = './trt_model' # 请替换为你想要保存TRT模型的路径\n",
    "\n",
    "# 定义一个函数来读取图像，这个函数需要根据你的实际情况来实现\n",
    "def load_images(file_name):\n",
    "    # 这里需要你自己实现如何从file_name读取图像并返回numpy数组\n",
    "    pass\n",
    "\n",
    "# 定义一个函数，这个函数将接受所有的输入并返回最后的输出\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32),\n",
    "])\n",
    "def model_func(input_decom, input_low_i, input_low_i_ratio, input_low_r):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, False)\n",
    "    return output_i, output_r\n",
    "\n",
    "# 转换模型\n",
    "concrete_func = model_func.get_concrete_function()\n",
    "\n",
    "# 将模型转换为TensorRT模型\n",
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "params = params._replace(max_workspace_size_bytes=(1<<32)) # 修改workspace大小\n",
    "params = params._replace(precision_mode=\"FP16\") # 设置推理精度\n",
    "params = params._replace(maximum_cached_engines=100) # 设置最大缓存引擎数量\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=params,\n",
    "    functions=[concrete_func]\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# 保存TensorRT模型\n",
    "converter.save(saved_model_dir_trt)\n",
    "\n",
    "# 加载优化后的模型进行推理\n",
    "root = tf.saved_model.load(saved_model_dir_trt)\n",
    "concrete_func = root.signatures['serving_default']\n",
    "\n",
    "# 读取输入数据\n",
    "test_data_files = glob(os.path.join(test_dir, '*.png')) # 假设你的测试数据是PNG图像\n",
    "test_data = [load_images(file) for file in test_data_files]\n",
    "\n",
    "# 对每一个输入数据进行推理，并保存结果\n",
    "results = []\n",
    "for x in test_data:\n",
    "    # 增加一个维度以匹配模型的输入要求\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = concrete_func(x)\n",
    "    results.append(y)\n",
    "\n",
    "# 在这里，results列表中包含了所有输入数据的推理结果\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 07:31:04.567680: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:936] TF-TRT Warning: Engine retrieval for input shapes: [[1,400,600,3]] failed. Running native segment for PartitionedCall/TRTEngineOp_000_000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fusion4': <tf.Tensor: shape=(1, 1, 400, 600, 3), dtype=float32, numpy=\n",
      "array([[[[[0.0434414 , 0.03047429, 0.02290096],\n",
      "          [0.06501768, 0.05392208, 0.03611331],\n",
      "          [0.07348678, 0.04627388, 0.04862572],\n",
      "          ...,\n",
      "          [0.03410219, 0.01493151, 0.01354985],\n",
      "          [0.03751391, 0.01650799, 0.01170312],\n",
      "          [0.03895836, 0.01907868, 0.01542505]],\n",
      "\n",
      "         [[0.04563245, 0.03064032, 0.03568611],\n",
      "          [0.06169915, 0.04334304, 0.03325764],\n",
      "          [0.05495221, 0.04613142, 0.04367299],\n",
      "          ...,\n",
      "          [0.04187234, 0.01825982, 0.02385909],\n",
      "          [0.04399507, 0.01707458, 0.01911527],\n",
      "          [0.02620247, 0.01565142, 0.01592946]],\n",
      "\n",
      "         [[0.04496914, 0.03003759, 0.02886588],\n",
      "          [0.05497001, 0.04105491, 0.0275457 ],\n",
      "          [0.04499306, 0.03976496, 0.03753095],\n",
      "          ...,\n",
      "          [0.05955804, 0.02189353, 0.03297251],\n",
      "          [0.07304651, 0.02460212, 0.03552938],\n",
      "          [0.03476525, 0.01825411, 0.0195179 ]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.26593608, 0.08567179, 0.12693365],\n",
      "          [0.4048427 , 0.1886067 , 0.26725563],\n",
      "          [0.17658718, 0.08873019, 0.19462092],\n",
      "          ...,\n",
      "          [0.00284118, 0.00364267, 0.00340297],\n",
      "          [0.00239467, 0.00293252, 0.00365479],\n",
      "          [0.00528961, 0.00416351, 0.00474445]],\n",
      "\n",
      "         [[0.2806685 , 0.14123014, 0.18300651],\n",
      "          [0.34861425, 0.18605942, 0.26157153],\n",
      "          [0.2001931 , 0.12149998, 0.2209014 ],\n",
      "          ...,\n",
      "          [0.00350696, 0.00473665, 0.00586736],\n",
      "          [0.00387285, 0.00514673, 0.0071323 ],\n",
      "          [0.00599852, 0.00473624, 0.00723337]],\n",
      "\n",
      "         [[0.23280737, 0.1523687 , 0.19744866],\n",
      "          [0.29381824, 0.20020676, 0.24647062],\n",
      "          [0.14242685, 0.09839921, 0.15978144],\n",
      "          ...,\n",
      "          [0.00773387, 0.00847816, 0.01177754],\n",
      "          [0.01041094, 0.01196963, 0.02091832],\n",
      "          [0.01309984, 0.01250311, 0.01491735]]]]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = tf.saved_model.load(\"./model/saved_model_trt\")\n",
    "\n",
    "# Define the inference function\n",
    "infer = model.signatures[\"serving_default\"]\n",
    "\n",
    "# Assuming your model takes an image as input, prepare a dummy input\n",
    "# Note: You'll need to adjust the shape and dtype to match your model's expected input.\n",
    "dummy_input = np.random.randn(1, 400, 600, 3).astype(np.float32)\n",
    "ratio_tensor = tf.constant(10.0)\n",
    "\n",
    "# Run inference\n",
    "output = infer(input_decom=tf.constant(dummy_input),ratio=ratio_tensor)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2393772/3980427902.py:11: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  im = im.resize((600, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94minfer time:0.034s\u001b[0m\n",
      "\u001b[94minfer time:0.124s\u001b[0m\n",
      "\u001b[94minfer time:0.043s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils import save_images\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "def load_images(file):\n",
    "    im = Image.open(file)\n",
    "    im = im.resize((600, 400), Image.ANTIALIAS)\n",
    "    img = np.array(im, dtype=\"float32\") / 255.0\n",
    "    img_max = np.max(img)\n",
    "    img_min = np.min(img)\n",
    "    img_norm = np.float32((img - img_min) / np.maximum((img_max - img_min), 0.001))\n",
    "    return img_norm\n",
    "\n",
    "def load_data(test_dir):\n",
    "    eval_low_data = []\n",
    "    eval_img_name = []\n",
    "    eval_low_data_name = glob(os.path.join(test_dir, 'low/*.png'))\n",
    "    eval_low_data_name.sort()\n",
    "    for idx in range(len(eval_low_data_name)):\n",
    "        [_, name] = os.path.split(eval_low_data_name[idx])\n",
    "        suffix = name[name.find('.') + 1:]\n",
    "        name = name[:name.find('.')]\n",
    "        eval_img_name.append(name)\n",
    "        eval_low_im = load_images(eval_low_data_name[idx])\n",
    "        eval_low_data.append(eval_low_im)\n",
    "    return eval_low_data, eval_img_name\n",
    "test_dir = \"./simple\"\n",
    "eval_low_data, eval_img_name = load_data(test_dir) \n",
    "for idx in range(len(eval_low_data)):\n",
    "    name = eval_img_name[idx]\n",
    "    input_low = eval_low_data[idx]\n",
    "    input_low_eval = np.expand_dims(input_low, axis=0)\n",
    "    ratio = float(10.0)\n",
    "    t1 = time.time()\n",
    "    output = infer(input_decom=tf.constant(input_low_eval),ratio = tf.constant(10.0))\n",
    "    t2 = time.time()\n",
    "    print(f\"\\033[94minfer time:{t2-t1:.3f}s\\033[0m\")\n",
    "    # print(f\"{output['fusion4']}\")\n",
    "    save_images(os.path.join(\"sample_results\", '%s_KinD_plus.png' % name), output['fusion4'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:13: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  concat = tf.layers.conv2d(input_i,\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:33: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:40: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind_layer:I_enhance_Net_ratio/Sigmoid,Denoise_Net/Sigmoid,DecomNet/Sigmoid,DecomNet/Sigmoid_1\n"
     ]
    }
   ],
   "source": [
    "# First, let's import necessary modules from TensorFlow\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()  # To make TensorFlow v1 code compatible with v2\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet,Illumination_adjust_curve_net_ratio,Restoration_net\n",
    "\n",
    "# Now let's try to build the model with a random input\n",
    "# Replace the real input image with a random tensor\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "input_image = tf.random.normal([1, 256, 256, 3])  # Assume the input image size is 256x256x3\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "# # Call the model building functions\n",
    "# R_low, I_low = DecomNet(input_image)\n",
    "# output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "# output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "# # Get the output nodes' names\n",
    "# R_low_name = R_low.op.name\n",
    "# I_low_name = I_low.op.name\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "\n",
    "# print(f\"layer names:{R_low_name}, {I_low_name},{output_i.op.name},{output_r.op.name}\")\n",
    "print(f\"kind_layer:{output_i.op.name},{output_r.op.name},{decom_output_R.op.name},{decom_output_I.op.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 19:32:52.740166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.740644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-04 19:32:52.742074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.742269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7827 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n",
      "/home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:13: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  concat = tf.layers.conv2d(input_i,\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:33: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:40: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputname:I_enhance_Net_ratio_5/Sigmoid\n",
      "outputname:Denoise_Net_5/Sigmoid\n",
      "outputname:DecomNet_5/Sigmoid\n",
      "outputname:DecomNet_5/Sigmoid_1\n",
      "[*] loaded ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n",
      "[*] loaded ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n",
      "[*] loaded ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n",
      "1023 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import os\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet, Illumination_adjust_curve_net_ratio, Restoration_net\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "\n",
    "# Create a session and make it the default session\n",
    "sess = tf.Session()\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "# Build the model\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "# Call the model building function\n",
    "output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "\n",
    "# Assume you have trained the model and the weights are loaded\n",
    "\n",
    "# We will save the model in the Protobuf format\n",
    "print(f\"outputname:{output_i.op.name}\")\n",
    "print(f\"outputname:{output_r.op.name}\")\n",
    "print(f\"outputname:{decom_output_R.op.name}\")\n",
    "print(f\"outputname:{decom_output_I.op.name}\")\n",
    "output_node_names = ['I_enhance_Net_ratio/Sigmoid', 'Denoise_Net/Sigmoid', 'DecomNet/Sigmoid', 'DecomNet/Sigmoid_1']\n",
    "input_node_names = ['input_decom', 'input_low_r', 'input_low_i', 'input_low_i_ratio', 'training']\n",
    "output_graph_name = './model.pb'\n",
    "checkpoint_dir = './experiment/exp2/checkpoint'\n",
    "illmin_name = \"illumination_adjust_curve_net_global_rm_del_rotate\"\n",
    "\n",
    "var_Decom = [var for var in tf.trainable_variables() if 'DecomNet' in var.name]\n",
    "var_adjust = [var for var in tf.trainable_variables() if 'I_enhance_Net' in var.name]\n",
    "var_restoration = [var for var in tf.trainable_variables() if 'Denoise_Net' in var.name]\n",
    "g_list = tf.global_variables()\n",
    "bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "var_restoration += bn_moving_vars\n",
    "saver_Decom = tf.train.Saver(var_list=var_Decom)\n",
    "saver_adjust = tf.train.Saver(var_list=var_adjust)\n",
    "saver_restoration = tf.train.Saver(var_list=var_restoration)\n",
    "decom_checkpoint_dir = os.path.join(checkpoint_dir, 'decom_net_retrain')\n",
    "ckpt_pre = tf.train.get_checkpoint_state(decom_checkpoint_dir)\n",
    "if ckpt_pre:\n",
    "    print('[*] loaded ' + ckpt_pre.model_checkpoint_path)\n",
    "    saver_Decom.restore(sess, ckpt_pre.model_checkpoint_path)\n",
    "else:\n",
    "    print('[*] No decomnet pretrained model!')\n",
    "\n",
    "checkpoint_dir_adjust = os.path.join(checkpoint_dir, illmin_name)\n",
    "ckpt_adjust = tf.train.get_checkpoint_state(checkpoint_dir_adjust)\n",
    "if ckpt_adjust:\n",
    "    print('[*] loaded ' + ckpt_adjust.model_checkpoint_path)\n",
    "    saver_adjust.restore(sess, ckpt_adjust.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No adjust net pretrained model!\")\n",
    "\n",
    "checkpoint_dir_restoration = os.path.join(checkpoint_dir, 'new_restoration_retrain')\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir_restoration)\n",
    "if ckpt:\n",
    "    print('[*] loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver_restoration.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No restoration net pretrained model!\")\n",
    "\n",
    "\n",
    "# Convert variables to constants and save the model\n",
    "output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess,  # The session is used to retrieve the weights\n",
    "    tf.get_default_graph().as_graph_def(),  # The graph_def is used to retrieve the nodes\n",
    "    output_node_names  # The output node names are used to define the usefull nodes\n",
    ")\n",
    "\n",
    "# Finally we serialize and dump the output graph to the filesystem\n",
    "with tf.gfile.GFile(output_graph_name, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "print(\"%d ops in the final graph.\" % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 19:37:51.577150: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:37:51.577809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:37:51.578328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:37:51.578890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:37:51.579082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-04 19:37:51.579422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:37:51.579648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7827 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'input:0' refers to a Tensor which does not exist. The operation, 'input', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Export the graph as a SavedModel\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mSession(graph\u001b[39m=\u001b[39mgraph) \u001b[39mas\u001b[39;00m sess:\n\u001b[1;32m     19\u001b[0m     tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msimple_save(sess,\n\u001b[1;32m     20\u001b[0m                                \u001b[39m'\u001b[39m\u001b[39msaved_model_dir\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m---> 21\u001b[0m                                inputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m: graph\u001b[39m.\u001b[39;49mget_tensor_by_name(\u001b[39m'\u001b[39;49m\u001b[39minput:0\u001b[39;49m\u001b[39m'\u001b[39;49m)},\n\u001b[1;32m     22\u001b[0m                                outputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m: graph\u001b[39m.\u001b[39mget_tensor_by_name(\u001b[39m'\u001b[39m\u001b[39moutput:0\u001b[39m\u001b[39m'\u001b[39m)})\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4172\u001b[0m, in \u001b[0;36mGraph.get_tensor_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(name, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   4170\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTensor names are strings (or similar), not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   4171\u001b[0m                   \u001b[39mtype\u001b[39m(name)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m-> 4172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mas_graph_element(name, allow_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, allow_operation\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3996\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3993\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n\u001b[1;32m   3995\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m-> 3996\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:4036\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   4034\u001b[0m   op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_name[op_name]\n\u001b[1;32m   4035\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4036\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe name \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m refers to a Tensor which does not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4037\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39mexist. The operation, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, does not exist in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4038\u001b[0m                  \u001b[39m\"\u001b[39m\u001b[39mgraph.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mrepr\u001b[39m(name), \u001b[39mrepr\u001b[39m(op_name)))\n\u001b[1;32m   4039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   4040\u001b[0m   \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39moutputs[out_n]\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'input:0' refers to a Tensor which does not exist. The operation, 'input', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet, Illumination_adjust_curve_net_ratio, Restoration_net\n",
    "\n",
    "# Load the .pb file\n",
    "with tf.gfile.GFile('model.pb', 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "\n",
    "# Import the graph_def into a new Graph\n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "# Export the graph as a SavedModel\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.saved_model.simple_save(sess,\n",
    "                               'saved_model_dir',\n",
    "                               inputs={'input': graph.get_tensor_by_name('input:0')},\n",
    "                               outputs={'output': graph.get_tensor_by_name('output:0')})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m conversion_params \u001b[39m=\u001b[39m trt\u001b[39m.\u001b[39mDEFAULT_TRT_CONVERSION_PARAMS\u001b[39m.\u001b[39m_replace(\n\u001b[1;32m      5\u001b[0m     max_workspace_size_bytes\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m<<\u001b[39m\u001b[39m32\u001b[39m),\n\u001b[1;32m      6\u001b[0m     precision_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFP16\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     maximum_cached_engines\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# Create a converter\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m converter \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mexperimental\u001b[39m.\u001b[39;49mtensorrt\u001b[39m.\u001b[39;49mConverter(\n\u001b[1;32m     11\u001b[0m     input_saved_model_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpath_to_save_trt_model\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     conversion_params\u001b[39m=\u001b[39;49mconversion_params)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Convert the model\u001b[39;00m\n\u001b[1;32m     15\u001b[0m converter\u001b[39m.\u001b[39mconvert()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    554\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    555\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    556\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    559\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[1;32m    560\u001b[0m           instructions)\n\u001b[0;32m--> 561\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py:1270\u001b[0m, in \u001b[0;36mTrtGraphConverterV2.__init__\u001b[0;34m(self, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, use_dynamic_shape, dynamic_shape_profile_strategy, max_workspace_size_bytes, enable_sparse_compute, precision_mode, minimum_segment_size, maximum_cached_engines, use_calibration, allow_build_at_runtime, dla_core, dla_fallback_layers, conversion_params)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m@deprecation\u001b[39m\u001b[39m.\u001b[39mdeprecated_args(\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1201\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mUse individual converter parameters instead\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1202\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mconversion_params\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1217\u001b[0m              dla_fallback_layers\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1218\u001b[0m              conversion_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1219\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Initialize the converter.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \n\u001b[1;32m   1221\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[39m    ValueError: if the combination of the parameters is invalid.\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m   \u001b[39massert\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m   1271\u001b[0m   \u001b[39mif\u001b[39;00m conversion_params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1272\u001b[0m     conversion_params \u001b[39m=\u001b[39m TrtConversionParams(\n\u001b[1;32m   1273\u001b[0m         max_workspace_size_bytes\u001b[39m=\u001b[39mmax_workspace_size_bytes,\n\u001b[1;32m   1274\u001b[0m         precision_mode\u001b[39m=\u001b[39mprecision_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         dla_core\u001b[39m=\u001b[39mdla_core,\n\u001b[1;32m   1281\u001b[0m         dla_fallback_layers\u001b[39m=\u001b[39mdla_fallback_layers)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(\n",
    "    max_workspace_size_bytes=(1<<32),\n",
    "    precision_mode=\"FP16\",\n",
    "    maximum_cached_engines=100)\n",
    "\n",
    "# Create a converter\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='path_to_save_trt_model',\n",
    "    conversion_params=conversion_params)\n",
    "\n",
    "# Convert the model\n",
    "converter.convert()\n",
    "\n",
    "# Save the optimized model\n",
    "converter.save('optimized_model.pb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

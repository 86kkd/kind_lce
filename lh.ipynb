{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:13: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  concat = tf.layers.conv2d(input_i,\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:33: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:40: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind_layer:I_enhance_Net_ratio/Sigmoid,Denoise_Net/Sigmoid,DecomNet/Sigmoid,DecomNet/Sigmoid_1\n"
     ]
    }
   ],
   "source": [
    "# First, let's import necessary modules from TensorFlow\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()  # To make TensorFlow v1 code compatible with v2\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet,Illumination_adjust_curve_net_ratio,Restoration_net\n",
    "\n",
    "# Now let's try to build the model with a random input\n",
    "# Replace the real input image with a random tensor\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "input_image = tf.random.normal([1, 256, 256, 3])  # Assume the input image size is 256x256x3\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "# # Call the model building functions\n",
    "# R_low, I_low = DecomNet(input_image)\n",
    "# output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "# output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "# # Get the output nodes' names\n",
    "# R_low_name = R_low.op.name\n",
    "# I_low_name = I_low.op.name\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "\n",
    "# print(f\"layer names:{R_low_name}, {I_low_name},{output_i.op.name},{output_r.op.name}\")\n",
    "print(f\"kind_layer:{output_i.op.name},{output_r.op.name},{decom_output_R.op.name},{decom_output_I.op.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 19:32:52.740166: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.740644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741056: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.741743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-04 19:32:52.742074: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-04 19:32:52.742269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7827 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n",
      "/home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:13: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  concat = tf.layers.conv2d(input_i,\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:33: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:40: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputname:I_enhance_Net_ratio_5/Sigmoid\n",
      "outputname:Denoise_Net_5/Sigmoid\n",
      "outputname:DecomNet_5/Sigmoid\n",
      "outputname:DecomNet_5/Sigmoid_1\n",
      "[*] loaded ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n",
      "[*] loaded ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n",
      "[*] loaded ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n",
      "1023 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import filters,color\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet, Illumination_adjust_curve_net_ratio, Restoration_net\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "\n",
    "# Create a session and make it the default session\n",
    "sess = tf.Session()\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "# Build the model\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "# Call the model building function\n",
    "output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "\n",
    "# Assume you have trained the model and the weights are loaded\n",
    "\n",
    "# We will save the model in the Protobuf format\n",
    "print(f\"outputname:{output_i.op.name}\")\n",
    "print(f\"outputname:{output_r.op.name}\")\n",
    "print(f\"outputname:{decom_output_R.op.name}\")\n",
    "print(f\"outputname:{decom_output_I.op.name}\")\n",
    "output_node_names = ['I_enhance_Net_ratio/Sigmoid', 'Denoise_Net/Sigmoid', 'DecomNet/Sigmoid', 'DecomNet/Sigmoid_1']\n",
    "input_node_names = ['input_decom', 'input_low_r', 'input_low_i', 'input_low_i_ratio', 'training']\n",
    "output_graph_name = './model.pb'\n",
    "checkpoint_dir = './experiment/exp2/checkpoint'\n",
    "illmin_name = \"illumination_adjust_curve_net_global_rm_del_rotate\"\n",
    "\n",
    "var_Decom = [var for var in tf.trainable_variables() if 'DecomNet' in var.name]\n",
    "var_adjust = [var for var in tf.trainable_variables() if 'I_enhance_Net' in var.name]\n",
    "var_restoration = [var for var in tf.trainable_variables() if 'Denoise_Net' in var.name]\n",
    "g_list = tf.global_variables()\n",
    "bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "var_restoration += bn_moving_vars\n",
    "saver_Decom = tf.train.Saver(var_list=var_Decom)\n",
    "saver_adjust = tf.train.Saver(var_list=var_adjust)\n",
    "saver_restoration = tf.train.Saver(var_list=var_restoration)\n",
    "decom_checkpoint_dir = os.path.join(checkpoint_dir, 'decom_net_retrain')\n",
    "ckpt_pre = tf.train.get_checkpoint_state(decom_checkpoint_dir)\n",
    "if ckpt_pre:\n",
    "    print('[*] loaded ' + ckpt_pre.model_checkpoint_path)\n",
    "    saver_Decom.restore(sess, ckpt_pre.model_checkpoint_path)\n",
    "else:\n",
    "    print('[*] No decomnet pretrained model!')\n",
    "\n",
    "checkpoint_dir_adjust = os.path.join(checkpoint_dir, illmin_name)\n",
    "ckpt_adjust = tf.train.get_checkpoint_state(checkpoint_dir_adjust)\n",
    "if ckpt_adjust:\n",
    "    print('[*] loaded ' + ckpt_adjust.model_checkpoint_path)\n",
    "    saver_adjust.restore(sess, ckpt_adjust.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No adjust net pretrained model!\")\n",
    "\n",
    "checkpoint_dir_restoration = os.path.join(checkpoint_dir, 'new_restoration_retrain')\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir_restoration)\n",
    "if ckpt:\n",
    "    print('[*] loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver_restoration.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No restoration net pretrained model!\")\n",
    "\n",
    "\n",
    "def infer(input_low, input_low_r, input_low_i, input_low_i_ratio):\n",
    "    input_low_eval = np.expand_dims(input_low, axis=0)\n",
    "    h, w, _ = input_low.shape\n",
    "    ratio = float(ratio)\n",
    "\n",
    "    decom_r_low, decom_i_low = sess.run([decom_output_R, decom_output_I], feed_dict={input_decom: input_low_eval})\n",
    "    restoration_r = sess.run(output_r, feed_dict={input_low_r: decom_r_low, input_low_i: decom_i_low, training: False})\n",
    "    # change the ratio to get different exposure level, the value can be 0-5.0\n",
    "        \n",
    "    i_low_data_ratio = np.ones([h, w]) * ratio\n",
    "    i_low_ratio_expand = np.expand_dims(i_low_data_ratio, axis=2)\n",
    "    i_low_ratio_expand2 = np.expand_dims(i_low_ratio_expand, axis=0)\n",
    "    adjust_i = sess.run(output_i, feed_dict={input_low_i: decom_i_low, input_low_i_ratio: i_low_ratio_expand2})\n",
    "    \n",
    "    # The restoration result can find more details from very dark regions, however, it will restore the very dark regions\n",
    "    # with gray colors, we use the following operator to alleviate this weakness.\n",
    "    decom_r_sq = np.squeeze(decom_r_low)\n",
    "    r_gray = color.rgb2gray(decom_r_sq)\n",
    "    r_gray_gaussion = filters.gaussian(r_gray, 3)\n",
    "    low_i = np.minimum((r_gray_gaussion * 2) ** 0.5, 1)\n",
    "    low_i_expand_0 = np.expand_dims(low_i, axis=0)\n",
    "    low_i_expand_3 = np.expand_dims(low_i_expand_0, axis=3)\n",
    "    result_denoise = restoration_r * low_i_expand_3\n",
    "    fusion4 = result_denoise * adjust_i\n",
    "    \n",
    "    return fusion4\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"./model/model.ckpt\")\n",
    "\n",
    "# Convert to SavedModel\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(\"./model/saved_model\")\n",
    "builder.add_meta_graph_and_variables(sess,\n",
    "                                      [tf.saved_model.tag_constants.SERVING],\n",
    "                                      signature_def_map= {\n",
    "                                          \"serving_default\": tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "                                              inputs= {\"input_decom\": input_decom, \"input_low_r\": input_low_r, \"input_low_i\": input_low_i, \"input_low_i_ratio\": input_low_i_ratio},\n",
    "                                              outputs= {\"output_i\": output_i, \"output_r\": output_r})\n",
    "                                      })\n",
    "builder.save() \n",
    "\n",
    "# Convert variables to constants and save the model\n",
    "output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess,  # The session is used to retrieve the weights\n",
    "    tf.get_default_graph().as_graph_def(),  # The graph_def is used to retrieve the nodes\n",
    "    output_node_names  # The output node names are used to define the usefull nodes\n",
    ")\n",
    "\n",
    "# Finally we serialize and dump the output graph to the filesystem\n",
    "with tf.gfile.GFile(output_graph_name, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "print(\"%d ops in the final graph.\" % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# For DecomNet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m decom_signature \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msignature_def_utils\u001b[39m.\u001b[39mpredict_signature_def(\n\u001b[1;32m      3\u001b[0m     inputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39minput_decom\u001b[39m\u001b[39m'\u001b[39m: input_decom},\n\u001b[1;32m      4\u001b[0m     outputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdecom_output_R\u001b[39m\u001b[39m'\u001b[39m: decom_output_R, \u001b[39m'\u001b[39m\u001b[39mdecom_output_I\u001b[39m\u001b[39m'\u001b[39m: decom_output_I})\n\u001b[1;32m      6\u001b[0m \u001b[39m# For I_enhance_Net\u001b[39;00m\n\u001b[1;32m      7\u001b[0m i_enhance_signature \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msignature_def_utils\u001b[39m.\u001b[39mpredict_signature_def(\n\u001b[1;32m      8\u001b[0m     inputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39minput_low_i\u001b[39m\u001b[39m'\u001b[39m: input_low_i, \u001b[39m'\u001b[39m\u001b[39minput_low_i_ratio\u001b[39m\u001b[39m'\u001b[39m: input_low_i_ratio},\n\u001b[1;32m      9\u001b[0m     outputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39moutput_i\u001b[39m\u001b[39m'\u001b[39m: output_i})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# For DecomNet\n",
    "decom_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_decom': input_decom},\n",
    "    outputs={'decom_output_R': decom_output_R, 'decom_output_I': decom_output_I})\n",
    "\n",
    "# For I_enhance_Net\n",
    "i_enhance_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_low_i': input_low_i, 'input_low_i_ratio': input_low_i_ratio},\n",
    "    outputs={'output_i': output_i})\n",
    "\n",
    "# For Denoise_Net\n",
    "denoise_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_low_r': input_low_r, 'input_low_i': input_low_i},\n",
    "    outputs={'output_r': output_r})\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess,\n",
    "                                      [tf.saved_model.tag_constants.SERVING],\n",
    "                                      signature_def_map={\n",
    "                                          \"decom\": decom_signature,\n",
    "                                          \"i_enhance\": i_enhance_signature,\n",
    "                                          \"denoise\": denoise_signature})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload(saved_model_dir)\n\u001b[1;32m      3\u001b[0m \u001b[39m# For DecomNet\u001b[39;00m\n\u001b[1;32m      4\u001b[0m decom_func \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39msignatures[\u001b[39m'\u001b[39m\u001b[39mdecom\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "# For DecomNet\n",
    "decom_func = loaded_model.signatures['decom']\n",
    "decom_output = decom_func(input_decom)\n",
    "\n",
    "# For I_enhance_Net\n",
    "i_enhance_func = loaded_model.signatures['i_enhance']\n",
    "i_enhance_output = i_enhance_func(input_low_i, input_low_i_ratio)\n",
    "\n",
    "# For Denoise_Net\n",
    "denoise_func = loaded_model.signatures['denoise']\n",
    "denoise_output = denoise_func(input_low_r, input_low_i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nvidia/.local/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:13: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  concat = tf.layers.conv2d(input_i,\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:33: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:40: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n",
      "/home/nvidia/Desktop/PommesPeter/lowlight-enhancement-research/KinD_plus/msia_BN_3_M.py:48: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  pu_conv = tf.layers.batch_normalization(pu_conv, training=training)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind_layer:I_enhance_Net_ratio/Sigmoid,Denoise_Net/Sigmoid,DecomNet/Sigmoid,DecomNet/Sigmoid_1\n"
     ]
    }
   ],
   "source": [
    "# First, let's import necessary modules from TensorFlow\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()  # To make TensorFlow v1 code compatible with v2\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet,Illumination_adjust_curve_net_ratio,Restoration_net\n",
    "\n",
    "# Now let's try to build the model with a random input\n",
    "# Replace the real input image with a random tensor\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "input_image = tf.random.normal([1, 256, 256, 3])  # Assume the input image size is 256x256x3\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "# # Call the model building functions\n",
    "# R_low, I_low = DecomNet(input_image)\n",
    "# output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "# output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "# # Get the output nodes' names\n",
    "# R_low_name = R_low.op.name\n",
    "# I_low_name = I_low.op.name\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "\n",
    "# print(f\"layer names:{R_low_name}, {I_low_name},{output_i.op.name},{output_r.op.name}\")\n",
    "print(f\"kind_layer:{output_i.op.name},{output_r.op.name},{decom_output_R.op.name},{decom_output_I.op.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 16:04:40.653496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 16:04:40.653949: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 16:04:40.654238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 16:04:40.654657: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 16:04:40.654773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-05 16:04:40.655085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-05 16:04:40.655306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6972 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputname:I_enhance_Net_ratio_4/Sigmoid\n",
      "outputname:Denoise_Net_4/Sigmoid\n",
      "outputname:DecomNet_4/Sigmoid\n",
      "outputname:DecomNet_4/Sigmoid_1\n",
      "[*] loaded ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/decom_net_retrain/Decomposition_Net.ckpt-150000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] loaded ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/illumination_adjust_curve_net_global_rm_del_rotate/Illumination_Adjustment_Net.ckpt-112000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] loaded ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n",
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./experiment/exp2/checkpoint/new_restoration_retrain/Reflectance_Restoration_Net.ckpt-2399\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: tf__infer() missing 1 required positional argument: 'input_low_i_ratio'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 111\u001b[0m\n\u001b[1;32m    106\u001b[0m     fusion4 \u001b[39m=\u001b[39m result_denoise \u001b[39m*\u001b[39m adjust_i\n\u001b[1;32m    108\u001b[0m     \u001b[39mreturn\u001b[39;00m fusion4\n\u001b[1;32m    110\u001b[0m signatures \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 111\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mserving_default\u001b[39m\u001b[39m'\u001b[39m: infer\u001b[39m.\u001b[39;49mget_concrete_function(\n\u001b[1;32m    112\u001b[0m         tf\u001b[39m.\u001b[39;49mTensorSpec(shape\u001b[39m=\u001b[39;49m(), dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mbool, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    113\u001b[0m         \u001b[39m# tf.TensorSpec(shape=[None, None, 3], dtype=tf.float32, name=\"input_low\"),\u001b[39;49;00m\n\u001b[1;32m    114\u001b[0m         tf\u001b[39m.\u001b[39;49mTensorSpec(shape\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m3\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput_decom\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    115\u001b[0m         tf\u001b[39m.\u001b[39;49mTensorSpec(shape\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m3\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput_low_r\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    116\u001b[0m         tf\u001b[39m.\u001b[39;49mTensorSpec(shape\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput_low_i\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    117\u001b[0m         tf\u001b[39m.\u001b[39;49mTensorSpec(shape\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m1\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mfloat32, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput_low_i_ratio\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m }\n\u001b[1;32m    121\u001b[0m \u001b[39m# Convert the function to a TensorFlow function\u001b[39;00m\n\u001b[1;32m    122\u001b[0m infer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(infer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1215\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1214\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1215\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1216\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1195\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1193\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1198\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1199\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:749\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 749\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    750\u001b[0m     \u001b[39m.\u001b[39;49m_get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    751\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds))\n\u001b[1;32m    753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    754\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:162\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 162\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:645\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 645\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    646\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1269\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1269\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   1270\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1258\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1258\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1259\u001b[0m       original_func,\n\u001b[1;32m   1260\u001b[0m       args,\n\u001b[1;32m   1261\u001b[0m       kwargs,\n\u001b[1;32m   1262\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1263\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1264\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1265\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1266\u001b[0m       ))\n\u001b[1;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__infer() missing 1 required positional argument: 'input_low_i_ratio'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import filters,color\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet, Illumination_adjust_curve_net_ratio, Restoration_net\n",
    "\n",
    "def KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    decom_output_R = R_decom\n",
    "    decom_output_I = I_decom\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, training)\n",
    "    \n",
    "    return output_i, output_r, decom_output_R, decom_output_I\n",
    "\n",
    "# Create a session and make it the default session\n",
    "sess = tf.Session()\n",
    "tf.keras.backend.set_session(sess)\n",
    "\n",
    "# Build the model\n",
    "input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "input_low_r = tf.placeholder(tf.float32, [None, None, None, 3], name='input_low_r')\n",
    "input_low_i = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i')\n",
    "input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "# Call the model building function\n",
    "\n",
    "\n",
    "# Assume you have trained the model and the weights are loaded\n",
    "\n",
    "# We will save the model in the Protobuf format\n",
    "print(f\"outputname:{output_i.op.name}\")\n",
    "print(f\"outputname:{output_r.op.name}\")\n",
    "print(f\"outputname:{decom_output_R.op.name}\")\n",
    "print(f\"outputname:{decom_output_I.op.name}\")\n",
    "output_node_names = ['I_enhance_Net_ratio/Sigmoid', 'Denoise_Net/Sigmoid', 'DecomNet/Sigmoid', 'DecomNet/Sigmoid_1']\n",
    "input_node_names = ['input_decom', 'input_low_r', 'input_low_i', 'input_low_i_ratio', 'training']\n",
    "output_graph_name = './model.pb'\n",
    "checkpoint_dir = './experiment/exp2/checkpoint'\n",
    "illmin_name = \"illumination_adjust_curve_net_global_rm_del_rotate\"\n",
    "\n",
    "var_Decom = [var for var in tf.trainable_variables() if 'DecomNet' in var.name]\n",
    "var_adjust = [var for var in tf.trainable_variables() if 'I_enhance_Net' in var.name]\n",
    "var_restoration = [var for var in tf.trainable_variables() if 'Denoise_Net' in var.name]\n",
    "g_list = tf.global_variables()\n",
    "bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "var_restoration += bn_moving_vars\n",
    "saver_Decom = tf.train.Saver(var_list=var_Decom)\n",
    "saver_adjust = tf.train.Saver(var_list=var_adjust)\n",
    "saver_restoration = tf.train.Saver(var_list=var_restoration)\n",
    "decom_checkpoint_dir = os.path.join(checkpoint_dir, 'decom_net_retrain')\n",
    "ckpt_pre = tf.train.get_checkpoint_state(decom_checkpoint_dir)\n",
    "if ckpt_pre:\n",
    "    print('[*] loaded ' + ckpt_pre.model_checkpoint_path)\n",
    "    saver_Decom.restore(sess, ckpt_pre.model_checkpoint_path)\n",
    "else:\n",
    "    print('[*] No decomnet pretrained model!')\n",
    "\n",
    "checkpoint_dir_adjust = os.path.join(checkpoint_dir, illmin_name)\n",
    "ckpt_adjust = tf.train.get_checkpoint_state(checkpoint_dir_adjust)\n",
    "if ckpt_adjust:\n",
    "    print('[*] loaded ' + ckpt_adjust.model_checkpoint_path)\n",
    "    saver_adjust.restore(sess, ckpt_adjust.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No adjust net pretrained model!\")\n",
    "\n",
    "checkpoint_dir_restoration = os.path.join(checkpoint_dir, 'new_restoration_retrain')\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir_restoration)\n",
    "if ckpt:\n",
    "    print('[*] loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver_restoration.restore(sess, ckpt.model_checkpoint_path)\n",
    "else:\n",
    "    print(\"[*] No restoration net pretrained model!\")\n",
    "\n",
    "@tf.function\n",
    "def infer(input_low,training, input_decom, input_low_r, input_low_i, input_low_i_ratio):\n",
    "    input_low_eval = tf.expand_dims(input_low, axis=0)\n",
    "    h, w, _ = input_low.shape.as_list()\n",
    "    ratio = float(ratio)\n",
    "    \n",
    "    output_i, output_r, decom_output_R, decom_output_I = KinD_LCE(input_decom, input_low_r, input_low_i, input_low_i_ratio, training)\n",
    "    decom_r_low, decom_i_low = sess.run([decom_output_R, decom_output_I], feed_dict={input_decom: input_low_eval})\n",
    "    restoration_r = sess.run(output_r, feed_dict={input_low_r: decom_r_low, input_low_i: decom_i_low, training: False})\n",
    "    # change the ratio to get different exposure level, the value can be 0-5.0\n",
    "        \n",
    "    i_low_data_ratio = np.ones([h, w]) * ratio\n",
    "    i_low_ratio_expand = np.expand_dims(i_low_data_ratio, axis=2)\n",
    "    i_low_ratio_expand2 = np.expand_dims(i_low_ratio_expand, axis=0)\n",
    "    adjust_i = sess.run(output_i, feed_dict={input_low_i: decom_i_low, input_low_i_ratio: i_low_ratio_expand2})\n",
    "    \n",
    "    # The restoration result can find more details from very dark regions, however, it will restore the very dark regions\n",
    "    # with gray colors, we use the following operator to alleviate this weakness.\n",
    "    decom_r_sq = np.squeeze(decom_r_low)\n",
    "    r_gray = color.rgb2gray(decom_r_sq)\n",
    "    r_gray_gaussion = filters.gaussian(r_gray, 3)\n",
    "    low_i = np.minimum((r_gray_gaussion * 2) ** 0.5, 1)\n",
    "    low_i_expand_0 = np.expand_dims(low_i, axis=0)\n",
    "    low_i_expand_3 = np.expand_dims(low_i_expand_0, axis=3)\n",
    "    result_denoise = restoration_r * low_i_expand_3\n",
    "    fusion4 = result_denoise * adjust_i\n",
    "    \n",
    "    return fusion4\n",
    "\n",
    "signatures = {\n",
    "    'serving_default': infer.get_concrete_function(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.bool, name=\"training\"),\n",
    "        # tf.TensorSpec(shape=[None, None, 3], dtype=tf.float32, name=\"input_low\"),\n",
    "        tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32, name=\"input_decom\"),\n",
    "        tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32, name=\"input_low_r\"),\n",
    "        tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32, name=\"input_low_i\"),\n",
    "        tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32, name=\"input_low_i_ratio\")\n",
    "    )\n",
    "}\n",
    "\n",
    "# Convert the function to a TensorFlow function\n",
    "infer = tf.function(infer)\n",
    "\n",
    "# Save the model\n",
    "tf.saved_model.save(infer, \"saved_model_dir\", signatures=signatures)\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "# save_path = saver.save(sess, \"./model/model.ckpt\")\n",
    "\n",
    "# # Convert to SavedModel\n",
    "# builder = tf.saved_model.builder.SavedModelBuilder(\"./model/saved_model\")\n",
    "# builder.add_meta_graph_and_variables(sess,\n",
    "#                                       [tf.saved_model.tag_constants.SERVING],\n",
    "#                                       signature_def_map= {\n",
    "#                                           \"serving_default\": tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "#                                               inputs= {\"input_decom\": input_decom, \"input_low_r\": input_low_r, \"input_low_i\": input_low_i, \"input_low_i_ratio\": input_low_i_ratio},\n",
    "#                                               outputs= {\"output_i\": output_i, \"output_r\": output_r})\n",
    "#                                       })\n",
    "# builder.save() \n",
    "\n",
    "# # Convert variables to constants and save the model\n",
    "# output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "#     sess,  # The session is used to retrieve the weights\n",
    "#     tf.get_default_graph().as_graph_def(),  # The graph_def is used to retrieve the nodes\n",
    "#     output_node_names  # The output node names are used to define the usefull nodes\n",
    "# )\n",
    "\n",
    "# # Finally we serialize and dump the output graph to the filesystem\n",
    "# with tf.gfile.GFile(output_graph_name, \"wb\") as f:\n",
    "#     f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "# print(\"%d ops in the final graph.\" % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# For DecomNet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m decom_signature \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msignature_def_utils\u001b[39m.\u001b[39mpredict_signature_def(\n\u001b[1;32m      3\u001b[0m     inputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39minput_decom\u001b[39m\u001b[39m'\u001b[39m: input_decom},\n\u001b[1;32m      4\u001b[0m     outputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mdecom_output_R\u001b[39m\u001b[39m'\u001b[39m: decom_output_R, \u001b[39m'\u001b[39m\u001b[39mdecom_output_I\u001b[39m\u001b[39m'\u001b[39m: decom_output_I})\n\u001b[1;32m      6\u001b[0m \u001b[39m# For I_enhance_Net\u001b[39;00m\n\u001b[1;32m      7\u001b[0m i_enhance_signature \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39msignature_def_utils\u001b[39m.\u001b[39mpredict_signature_def(\n\u001b[1;32m      8\u001b[0m     inputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39minput_low_i\u001b[39m\u001b[39m'\u001b[39m: input_low_i, \u001b[39m'\u001b[39m\u001b[39minput_low_i_ratio\u001b[39m\u001b[39m'\u001b[39m: input_low_i_ratio},\n\u001b[1;32m      9\u001b[0m     outputs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39moutput_i\u001b[39m\u001b[39m'\u001b[39m: output_i})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# For DecomNet\n",
    "decom_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_decom': input_decom},\n",
    "    outputs={'decom_output_R': decom_output_R, 'decom_output_I': decom_output_I})\n",
    "\n",
    "# For I_enhance_Net\n",
    "i_enhance_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_low_i': input_low_i, 'input_low_i_ratio': input_low_i_ratio},\n",
    "    outputs={'output_i': output_i})\n",
    "\n",
    "# For Denoise_Net\n",
    "denoise_signature = tf.saved_model.signature_def_utils.predict_signature_def(\n",
    "    inputs={'input_low_r': input_low_r, 'input_low_i': input_low_i},\n",
    "    outputs={'output_r': output_r})\n",
    "\n",
    "builder.add_meta_graph_and_variables(sess,\n",
    "                                      [tf.saved_model.tag_constants.SERVING],\n",
    "                                      signature_def_map={\n",
    "                                          \"decom\": decom_signature,\n",
    "                                          \"i_enhance\": i_enhance_signature,\n",
    "                                          \"denoise\": denoise_signature})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload(saved_model_dir)\n\u001b[1;32m      3\u001b[0m \u001b[39m# For DecomNet\u001b[39;00m\n\u001b[1;32m      4\u001b[0m decom_func \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39msignatures[\u001b[39m'\u001b[39m\u001b[39mdecom\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "# For DecomNet\n",
    "decom_func = loaded_model.signatures['decom']\n",
    "decom_output = decom_func(input_decom)\n",
    "\n",
    "# For I_enhance_Net\n",
    "i_enhance_func = loaded_model.signatures['i_enhance']\n",
    "i_enhance_output = i_enhance_func(input_low_i, input_low_i_ratio)\n",
    "\n",
    "# For Denoise_Net\n",
    "denoise_func = loaded_model.signatures['denoise']\n",
    "denoise_output = denoise_func(input_low_r, input_low_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python.framework import graph_io\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import filters,color\n",
    "\n",
    "# Assume the model functions are already defined\n",
    "from model import DecomNet, Illumination_adjust_curve_net_ratio, Restoration_net\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 占位符\n",
    "    input_decom = tf.placeholder(tf.float32, [None, None, None, 3], name='input_decom')\n",
    "    input_low_i_ratio = tf.placeholder(tf.float32, [None, None, None, 1], name='input_low_i_ratio')\n",
    "\n",
    "    # 模型结构\n",
    "    decom_r_low, decom_i_low = DecomNet(input_decom)\n",
    "    restoration_r = Restoration_net(decom_r_low, decom_i_low, training=False)\n",
    "    \n",
    "    h, w, _ = tf.shape(input_decom)[1], tf.shape(input_decom)[2], tf.shape(input_decom)[3]\n",
    "    i_low_data_ratio = tf.ones([h, w]) * input_low_i_ratio\n",
    "    i_low_ratio_expand = tf.expand_dims(i_low_data_ratio, axis=2)\n",
    "    i_low_ratio_expand2 = tf.expand_dims(i_low_ratio_expand, axis=0)\n",
    "    \n",
    "    adjust_i, A = Illumination_adjust_curve_net_ratio(decom_i_low, i_low_ratio_expand2)\n",
    "    \n",
    "    decom_r_sq = tf.squeeze(decom_r_low)\n",
    "    r_gray = tf.image.rgb_to_grayscale(decom_r_sq)\n",
    "    r_gray_gaussian = tf.image.gaussian_filter2d(r_gray, filter_shape=(3, 3), sigma=3)\n",
    "    low_i = tf.minimum(tf.sqrt(r_gray_gaussian * 2), 1)\n",
    "    low_i_expand_3 = tf.expand_dims(low_i, axis=3)\n",
    "    result_denoise = restoration_r * low_i_expand_3\n",
    "    result_denoise = restoration_r * low_i_expand_3\n",
    "    fusion4 = result_denoise * adjust_i\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        # savemode\n",
    "        checkpoint_dir = './experiment/exp2/checkpoint'\n",
    "        illmin_name = \"illumination_adjust_curve_net_global_rm_del_rotate\"\n",
    "\n",
    "        # Create a session and make it the default session\n",
    "        sess = tf.Session()\n",
    "        tf.keras.backend.set_session(sess)\n",
    "        var_Decom = [var for var in tf.trainable_variables() if 'DecomNet' in var.name]\n",
    "        var_adjust = [var for var in tf.trainable_variables() if 'I_enhance_Net' in var.name]\n",
    "        var_restoration = [var for var in tf.trainable_variables() if 'Denoise_Net' in var.name]\n",
    "        g_list = tf.global_variables()\n",
    "        bn_moving_vars = [g for g in g_list if 'moving_mean' in g.name]\n",
    "        bn_moving_vars += [g for g in g_list if 'moving_variance' in g.name]\n",
    "        var_restoration += bn_moving_vars\n",
    "        saver_Decom = tf.train.Saver(var_list=var_Decom)\n",
    "        saver_adjust = tf.train.Saver(var_list=var_adjust)\n",
    "        saver_restoration = tf.train.Saver(var_list=var_restoration)\n",
    "        decom_checkpoint_dir = os.path.join(checkpoint_dir, 'decom_net_retrain')\n",
    "        ckpt_pre = tf.train.get_checkpoint_state(decom_checkpoint_dir)\n",
    "        if ckpt_pre:\n",
    "            print('[*] loaded ' + ckpt_pre.model_checkpoint_path)\n",
    "            saver_Decom.restore(sess, ckpt_pre.model_checkpoint_path)\n",
    "        else:\n",
    "            print('[*] No decomnet pretrained model!')\n",
    "\n",
    "        checkpoint_dir_adjust = os.path.join(checkpoint_dir, illmin_name)\n",
    "        ckpt_adjust = tf.train.get_checkpoint_state(checkpoint_dir_adjust)\n",
    "        if ckpt_adjust:\n",
    "            print('[*] loaded ' + ckpt_adjust.model_checkpoint_path)\n",
    "            saver_adjust.restore(sess, ckpt_adjust.model_checkpoint_path)\n",
    "        else:\n",
    "            print(\"[*] No adjust net pretrained model!\")\n",
    "\n",
    "        checkpoint_dir_restoration = os.path.join(checkpoint_dir, 'new_restoration_retrain')\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir_restoration)\n",
    "        if ckpt:\n",
    "            print('[*] loaded ' + ckpt.model_checkpoint_path)\n",
    "            saver_restoration.restore(sess, ckpt.model_checkpoint_path)\n",
    "        else:\n",
    "            print(\"[*] No restoration net pretrained model!\")\n",
    "\n",
    "        # feed_dict = {\n",
    "        #     input_decom: input_low_eval,\n",
    "        #     input_low_i_ratio: ratio,\n",
    "        #     # ... 添加其他的 feed_dict 值\n",
    "        # }\n",
    "        # output = sess.run(fusion4, feed_dict=feed_dict)\n",
    "        # saver.save(sess, \"model/model.ckpt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

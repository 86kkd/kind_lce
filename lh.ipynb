{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "print(\"\\033[92mstart load model\\033[0m\")\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=\"./model/saved_model\")\n",
    "print(\"\\033[92mload model successfully\\033[0m\")\n",
    "converter.convert()\n",
    "converter.save(\"./model/saved_model_trt\")\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 21:05:35.552139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:35.687342: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:35.687863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 21:05:35.693931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:35.694367: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:35.694673: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:37.453291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:37.453770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:37.453930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-03 21:05:37.454227: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:37.454472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8046 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "INFO:tensorflow:Linked TensorRT version: (8, 5, 2)\n",
      "INFO:tensorflow:Loaded TensorRT version: (8, 5, 2)\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/weights:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv1_1/biases:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/weights:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv2_1/biases:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'DecomNet/g_conv3_1/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 21:05:47.837890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.838154: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-08-03 21:05:47.838600: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-08-03 21:05:47.839733: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.840225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.840606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.841035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.841176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-03 21:05:47.841431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:47.841621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8046 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing prior device assignments in loaded saved model\n",
      "INFO:tensorflow:Automatic mixed precision will be used on the whole TensorFlow Graph. This behavior can be deactivated using the environment variable: TF_TRT_EXPERIMENTAL_FEATURES=deactivate_mixed_precision.\n",
      "More information can be found on: https://www.tensorflow.org/guide/mixed_precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 21:05:54.046361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.046628: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2023-08-03 21:05:54.046959: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-08-03 21:05:54.048156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.048526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.048834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.049284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.049418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1708] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-03 21:05:54.049690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-03 21:05:54.049862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1621] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8046 MB memory:  -> device: 0, name: Xavier, pci bus id: 0000:00:00.0, compute capability: 7.2\n",
      "2023-08-03 21:05:54.568914: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2373] Running auto_mixed_precision graph optimizer\n",
      "2023-08-03 21:05:54.600910: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 1004\n",
      "Recognized nodes available for conversion: 685\n",
      "Total nodes converted: 257\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 2\n",
      "Allowlisted nodes converted: 61\n",
      "Denylisted nodes blocking conversion: 8\n",
      "Nodes blocked from conversion by denylisted nodes: 25\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.118404: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:210] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.\n",
      "2023-08-03 21:05:55.216741: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:952] \n",
      "\n",
      "################################################################################\n",
      "TensorRT unsupported/non-converted OP Report:\n",
      "\t- Switch -> 60x\n",
      "\t- StridedSlice -> 36x\n",
      "\t- FusedBatchNormV3 -> 24x\n",
      "\t- Mul -> 24x\n",
      "\t- Conv2DBackpropInput -> 12x\n",
      "\t- Merge -> 12x\n",
      "\t- Pack -> 12x\n",
      "\t- Shape -> 12x\n",
      "\t- Placeholder -> 4x\n",
      "\t- NoOp -> 2x\n",
      "\t- Sigmoid -> 2x\n",
      "\t- PlaceholderWithDefault -> 1x\n",
      "\t- Split -> 1x\n",
      "--------------------------------------------------------------------------------\n",
      "\t- Total nonconverted OPs: 202\n",
      "\t- Total nonconverted OP Types: 13\n",
      "For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.\n",
      "################################################################################\n",
      "\n",
      "2023-08-03 21:05:55.247978: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1229] A total of 26 segments with at least minimum_segment_size=3 nodes have been found. TF-TRT will only convert the 20 largest segments. You can change this behavior by modifying the environment variable TF_TRT_MAX_ALLOWED_ENGINES=20\n",
      "2023-08-03 21:05:55.248729: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:802] Number of TensorRT candidate segments: 20\n",
      "2023-08-03 21:05:55.295098: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 0 consisting of 50 nodes by TRTEngineOp_000_000.\n",
      "2023-08-03 21:05:55.295881: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 1 consisting of 24 nodes by TRTEngineOp_000_001.\n",
      "2023-08-03 21:05:55.296260: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 2 consisting of 13 nodes by TRTEngineOp_000_002.\n",
      "2023-08-03 21:05:55.296678: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 3 consisting of 25 nodes by TRTEngineOp_000_003.\n",
      "2023-08-03 21:05:55.297101: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 4 consisting of 5 nodes by TRTEngineOp_000_004.\n",
      "2023-08-03 21:05:55.297453: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 5 consisting of 6 nodes by TRTEngineOp_000_005.\n",
      "2023-08-03 21:05:55.297742: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 6 consisting of 6 nodes by TRTEngineOp_000_006.\n",
      "2023-08-03 21:05:55.298040: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 7 consisting of 4 nodes by TRTEngineOp_000_007.\n",
      "2023-08-03 21:05:55.298335: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 8 consisting of 25 nodes by TRTEngineOp_000_008.\n",
      "2023-08-03 21:05:55.298717: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 9 consisting of 5 nodes by TRTEngineOp_000_009.\n",
      "2023-08-03 21:05:55.298999: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 10 consisting of 6 nodes by TRTEngineOp_000_010.\n",
      "2023-08-03 21:05:55.299304: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 11 consisting of 6 nodes by TRTEngineOp_000_011.\n",
      "2023-08-03 21:05:55.299630: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 12 consisting of 25 nodes by TRTEngineOp_000_012.\n",
      "2023-08-03 21:05:55.300099: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 13 consisting of 5 nodes by TRTEngineOp_000_013.\n",
      "2023-08-03 21:05:55.300443: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 14 consisting of 6 nodes by TRTEngineOp_000_014.\n",
      "2023-08-03 21:05:55.300764: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 15 consisting of 6 nodes by TRTEngineOp_000_015.\n",
      "2023-08-03 21:05:55.301047: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 16 consisting of 5 nodes by TRTEngineOp_000_016.\n",
      "2023-08-03 21:05:55.301327: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 17 consisting of 6 nodes by TRTEngineOp_000_017.\n",
      "2023-08-03 21:05:55.301604: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 18 consisting of 6 nodes by TRTEngineOp_000_018.\n",
      "2023-08-03 21:05:55.301975: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:919] Replaced segment 19 consisting of 33 nodes by TRTEngineOp_000_019.\n",
      "2023-08-03 21:05:55.381501: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.399145: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 4\n",
      "Recognized nodes available for conversion: 3\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.407753: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.417707: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.428441: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 15\n",
      "Recognized nodes available for conversion: 8\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 2\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.445580: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 5\n",
      "Recognized nodes available for conversion: 3\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.471341: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 28\n",
      "Recognized nodes available for conversion: 18\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 3\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.505940: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.539513: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 28\n",
      "Recognized nodes available for conversion: 18\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 3\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.596849: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 57\n",
      "Recognized nodes available for conversion: 36\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 8\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.627363: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 5\n",
      "Recognized nodes available for conversion: 3\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.636548: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.650475: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 28\n",
      "Recognized nodes available for conversion: 18\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 3\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.677237: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 28\n",
      "Recognized nodes available for conversion: 16\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 3\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.698294: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1547] No allowlist ops found, nothing to do\n",
      "2023-08-03 21:05:55.717406: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.726902: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.738189: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 5\n",
      "Recognized nodes available for conversion: 3\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.754604: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 6\n",
      "Recognized nodes available for conversion: 4\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n",
      "2023-08-03 21:05:55.763656: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1209] Automatic Mixed Precision Grappler Pass Summary:\n",
      "\n",
      "Total processable nodes: 5\n",
      "Recognized nodes available for conversion: 3\n",
      "Total nodes converted: 0\n",
      "Total FP16 Cast ops used (excluding Const and Variable casts): 0\n",
      "Allowlisted nodes converted: 1\n",
      "Denylisted nodes blocking conversion: 0\n",
      "Nodes blocked from conversion by denylisted nodes: 0\n",
      "\n",
      "For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:\n",
      "https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find TRTEngineOp_000_002 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_000 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_004 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_005 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_006 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_019 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_003 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_007 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_009 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_010 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_011 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_008 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_013 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_014 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_015 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_012 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_016 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_017 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_018 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_000_001 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Assets written to: path_to_save_trt_model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 定义一个函数来读取图像，这个函数需要根据你的实际情况来实现\n",
    "def load_images(file_name):\n",
    "    # 这里需要你自己实现如何从file_name读取图像并返回numpy数组\n",
    "    pass\n",
    "\n",
    "# 1. 加载已经训练好的TensorFlow模型\n",
    "saved_model_dir = './model/saved_model' # 请替换为你的模型路径\n",
    "model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "# 2. 使用TensorRT进行模型优化\n",
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "params = params._replace(max_workspace_size_bytes=(1<<32)) # 修改workspace大小\n",
    "params = params._replace(precision_mode=\"FP16\") # 设置推理精度\n",
    "params = params._replace(maximum_cached_engines=100) # 设置最大缓存引擎数量\n",
    "\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=params\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# 3. 对模型进行序列化并保存\n",
    "saved_model_dir_trt = 'path_to_save_trt_model' # 请替换为你想要保存TRT模型的路径\n",
    "converter.save(saved_model_dir_trt)\n",
    "\n",
    "# 4. 加载优化后的模型进行推理\n",
    "root = tf.saved_model.load(saved_model_dir_trt)\n",
    "concrete_func = root.signatures['serving_default']\n",
    "\n",
    "# 读取输入数据\n",
    "test_dir = '/path_to_your_test_data' # 请替换为你的测试数据目录\n",
    "test_data_files = glob(os.path.join(test_dir, '*.png')) # 假设你的测试数据是PNG图像\n",
    "test_data = [load_images(file) for file in test_data_files]\n",
    "\n",
    "# 对每一个输入数据进行推理，并保存结果\n",
    "results = []\n",
    "for x in test_data:\n",
    "    # 增加一个维度以匹配模型的输入要求\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = concrete_func(x)\n",
    "    results.append(y)\n",
    "\n",
    "# 在这里，results列表中包含了所有输入数据的推理结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from model import *\n",
    "\n",
    "saved_model_dir = \"./model/saved_model\"\n",
    "test_dir = '/simple/low' # 请替换为你的测试数据目录\n",
    "saved_model_dir_trt = './trt_model' # 请替换为你想要保存TRT模型的路径\n",
    "\n",
    "# 定义一个函数来读取图像，这个函数需要根据你的实际情况来实现\n",
    "def load_images(file_name):\n",
    "    # 这里需要你自己实现如何从file_name读取图像并返回numpy数组\n",
    "    pass\n",
    "\n",
    "# 定义一个函数，这个函数将接受所有的输入并返回最后的输出\n",
    "@tf.function(input_signature=[\n",
    "    tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 3], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=[None, None, None, 1], dtype=tf.float32),\n",
    "])\n",
    "def model_func(input_decom, input_low_i, input_low_i_ratio, input_low_r):\n",
    "    [R_decom, I_decom] = DecomNet(input_decom)\n",
    "    output_i, A = Illumination_adjust_curve_net_ratio(input_low_i, input_low_i_ratio)\n",
    "    output_r = Restoration_net(input_low_r, input_low_i, False)\n",
    "    return output_i, output_r\n",
    "\n",
    "# 转换模型\n",
    "concrete_func = model_func.get_concrete_function()\n",
    "\n",
    "# 将模型转换为TensorRT模型\n",
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "params = params._replace(max_workspace_size_bytes=(1<<32)) # 修改workspace大小\n",
    "params = params._replace(precision_mode=\"FP16\") # 设置推理精度\n",
    "params = params._replace(maximum_cached_engines=100) # 设置最大缓存引擎数量\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir=saved_model_dir,\n",
    "    conversion_params=params,\n",
    "    functions=[concrete_func]\n",
    ")\n",
    "converter.convert()\n",
    "\n",
    "# 保存TensorRT模型\n",
    "converter.save(saved_model_dir_trt)\n",
    "\n",
    "# 加载优化后的模型进行推理\n",
    "root = tf.saved_model.load(saved_model_dir_trt)\n",
    "concrete_func = root.signatures['serving_default']\n",
    "\n",
    "# 读取输入数据\n",
    "test_data_files = glob(os.path.join(test_dir, '*.png')) # 假设你的测试数据是PNG图像\n",
    "test_data = [load_images(file) for file in test_data_files]\n",
    "\n",
    "# 对每一个输入数据进行推理，并保存结果\n",
    "results = []\n",
    "for x in test_data:\n",
    "    # 增加一个维度以匹配模型的输入要求\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    y = concrete_func(x)\n",
    "    results.append(y)\n",
    "\n",
    "# 在这里，results列表中包含了所有输入数据的推理结果\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
